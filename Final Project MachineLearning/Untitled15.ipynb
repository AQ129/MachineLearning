{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "52100924-Nguyễn Văn Anh Quân\n",
        "52100922-Lê Phạm Hoàng Phương"
      ],
      "metadata": {
        "id": "4ebLAHShZClJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1)Phân tích thống kê trên dữ liệu, vẽ các đồ thị để hiểu bài toán, hiểu dữ liệu. Tìm hiểu các đặc trưng và đánh gía vai trò của các đặc trưng đối với mục tiêu bài toán;\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/bank-additional.csv', delimiter=';')\n",
        "\n",
        "# Xem thông tin cơ bản về dữ liệu\n",
        "print(\"Thông tin cơ bản về dữ liệu:\")\n",
        "print(data.head())\n",
        "print(\"\\nThông tin thống kê mô tả của dữ liệu:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Phân tích biến mục tiêu\n",
        "target_counts = data['y'].value_counts()\n",
        "print(\"\\nSố lượng và phân bố của biến mục tiêu:\")\n",
        "print(target_counts)\n",
        "plt.figure(figsize=(6, 4))\n",
        "target_counts.plot(kind='bar')\n",
        "plt.xlabel('Biến mục tiêu')\n",
        "plt.ylabel('Số lượng')\n",
        "plt.title('Phân bố của biến mục tiêu')\n",
        "plt.show()\n",
        "\n",
        "# Xem các đặc trưng\n",
        "features = data.drop('y', axis=1)\n",
        "print(\"\\nCác đặc trưng:\")\n",
        "print(features.head())\n",
        "\n",
        "# Mã hóa one-hot cho các đặc trưng chuỗi\n",
        "categorical_features = features.select_dtypes(include=['object']).columns\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "encoded_features = encoder.fit_transform(features[categorical_features])\n",
        "\n",
        "# Tạo danh sách tên đặc trưng đã mã hóa\n",
        "encoded_feature_names = []\n",
        "for i, column in enumerate(categorical_features):\n",
        "    unique_values = features[column].unique()\n",
        "    for value in unique_values:\n",
        "        encoded_feature_names.append(f'{column}_{value}')\n",
        "\n",
        "# Tạo DataFrame từ các đặc trưng đã mã hóa\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
        "\n",
        "# Kết hợp các đặc trưng đã mã hóa với các đặc trưng số\n",
        "features_encoded = pd.concat([features.drop(categorical_features, axis=1), encoded_df], axis=1)\n",
        "\n",
        "# Chia dữ liệu thành đặc trưng và biến mục tiêu\n",
        "X = features_encoded\n",
        "y = data['y']\n",
        "\n",
        "# Xây dựng mô hình RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Đào tạo mô hình trên dữ liệu\n",
        "model.fit(X, y)\n",
        "\n",
        "# Đánh giá độ quan trọng của các đặc trưng\n",
        "feature_importances = model.feature_importances_\n",
        "print(\"\\nĐộ quan trọng của các đặc trưng:\")\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(feature, ':', importance)"
      ],
      "metadata": {
        "id": "ZN0ZOWV6jT_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2)Ứng dụng các mô hình học máy cơ bản để giải quyết bài toán, bao gồm cả các mô hình thuộc Ensemble Learing;\n",
        "#4)Áp dụng các kỹ thuật tránh Overfiting trên các mô hình của câu (2) để giải quyết bài toán;\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/data/bank-additional.csv\", sep=\";\")\n",
        "\n",
        "# Chọn các đặc trưng và biến mục tiêu\n",
        "features = data.drop(\"y\", axis=1)\n",
        "target = data[\"y\"]\n",
        "\n",
        "# Chuyển đổi các biến hạng mục thành dạng số\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Sử dụng mô hình Naive Bayes với kiểm soát tham số làm mịn\n",
        "nb_model = GaussianNB(var_smoothing=1e-9)\n",
        "\n",
        "# Sử dụng mô hình Naive Bayes Classifier không thuộc Ensemble Learing\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Độ chính xác của mô hình Naive Bayes Classifier: {:.2f}\".format(accuracy))\n",
        "\n",
        "# Sử dụng K-Nearest Neighbors với kiểm soát tham số k\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "# Tạo pipeline với StandardScaler và K-Nearest Neighbors\n",
        "knn_model_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5))\n",
        "\n",
        "#Sử dụng K-Nearest Neighbors không thuộc Ensemble Learing\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model_pipe.fit(X_train, y_train)\n",
        "knn_y_pred = knn_model_pipe.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "print(\"Độ chính xác của mô hình K-Nearest Neighbors: {:.2f}\".format(knn_accuracy))\n",
        "\n",
        "# Áp dụng kiểm soát độ sâu của cây cho Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "#Sử dụng Random Forest thuộc Ensemble Learing\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "print(\"Độ chính xác của mô hình Random Forest: {:.2f}\".format(rf_accuracy))\n",
        "\n",
        "# Áp dụng kiểm soát kích thước của mô hình cho Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# Sử dụng Gradient Boosting thuộc Ensemble Learing\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_y_pred = gb_model.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
        "print(\"Độ chính xác của mô hình Gradient Boosting: {:.2f}\".format(gb_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "WPH19dSqCT4f",
        "outputId": "658e85cc-919e-4863-daf7-e99b25d25fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Độ chính xác của mô hình Naive Bayes Classifier: 0.83\n",
            "Độ chính xác của mô hình K-Nearest Neighbors: 0.91\n",
            "Độ chính xác của mô hình Random Forest: 0.89\n",
            "Độ chính xác của mô hình Gradient Boosting: 0.90\n",
            "Confusion Matrix:\n",
            "[[708  24]\n",
            " [ 54  38]]\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \"\"\"\n\u001b[0;32m--> 781\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-84db8cdd770d>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# In classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClassification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# `y_pred` given by the classifier will also be encoded with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# strings. So we raise a meaningful error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0;34m\"Labels in y_true and y_pred should be of the same type. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0;34mf\"Got y_true={np.unique(y_true)} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['no' 'yes'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3)Sử dụng Feed Forward Neural Network để giải quyết bài toán;\n",
        "#4)Áp dụng các kỹ thuật tránh Overfiting trên các mô hình của câu (3) để giải quyết bài toán;\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/data/bank-additional.csv\", sep=\";\")\n",
        "\n",
        "# Chọn các đặc trưng và biến mục tiêu\n",
        "features = data.drop(\"y\", axis=1)\n",
        "target = data[\"y\"]\n",
        "\n",
        "# Chuyển đổi biến mục tiêu thành dạng số bằng Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "target_encoded = label_encoder.fit_transform(target)  # Convert 'yes' to 1 and 'no' to 0\n",
        "\n",
        "# Chuyển đổi các biến hạng mục thành dạng số bằng Label Encoding và One-Hot Encoding\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
        "features_encoded = pd.get_dummies(features, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Chuẩn hóa dữ liệu\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Xây dựng mô hình Feed Forward Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dropout(0.5))  # Thêm lớp dropout để tránh overfitting\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "#Dùng early stopping để dừng quá trình huấn luyện khi độ chính xác trên tập kiểm tra ngừng cải thiện, giúp tránh overfitting.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)   # Dừng sau 3 epochs không có cải thiện\n",
        "# Compile mô hình\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Đánh giá mô hình\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Độ chính xác của mô hình Feed Forward Neural Network: {:.2f}\".format(accuracy))\n",
        "\n",
        "# In confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# In classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_binary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpPxZbfuDqER",
        "outputId": "0e94fb09-9097-4715-8623-3f99ea781535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "103/103 [==============================] - 3s 8ms/step - loss: 0.3674 - accuracy: 0.8707 - val_loss: 0.2745 - val_accuracy: 0.8993\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.2693 - accuracy: 0.8953 - val_loss: 0.2360 - val_accuracy: 0.9017\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9062 - val_loss: 0.2219 - val_accuracy: 0.9005\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9047 - val_loss: 0.2176 - val_accuracy: 0.9017\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9165 - val_loss: 0.2074 - val_accuracy: 0.9041\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9132 - val_loss: 0.2038 - val_accuracy: 0.9005\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1871 - accuracy: 0.9187 - val_loss: 0.2072 - val_accuracy: 0.9017\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9187 - val_loss: 0.2045 - val_accuracy: 0.9066\n",
            "Epoch 9/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9196 - val_loss: 0.2049 - val_accuracy: 0.9029\n",
            "26/26 [==============================] - 0s 2ms/step\n",
            "Độ chính xác của mô hình Feed Forward Neural Network: 0.90\n",
            "Confusion Matrix:\n",
            "[[708  24]\n",
            " [ 54  38]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       732\n",
            "           1       0.57      0.42      0.49        92\n",
            "\n",
            "    accuracy                           0.90       824\n",
            "   macro avg       0.75      0.69      0.72       824\n",
            "weighted avg       0.89      0.90      0.89       824\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBJkHkU8I59M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3)Sử dụng Reccurent Neural Network (hoặc mô thuộc loại này) để giải quyết bài toán;\n",
        "#4)Áp dụng các kỹ thuật tránh Overfiting trên các mô hình của câu (3) để giải quyết bài toán;\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/data/bank-additional.csv\", sep=\";\")\n",
        "\n",
        "# Chọn các đặc trưng và biến mục tiêu\n",
        "features = data.drop(\"y\", axis=1)\n",
        "target = data[\"y\"]\n",
        "\n",
        "# Chuyển đổi biến mục tiêu thành dạng số bằng Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "target_encoded = label_encoder.fit_transform(target)  # Convert 'yes' to 1 and 'no' to 0\n",
        "\n",
        "# Chuyển đổi các biến hạng mục thành dạng số bằng Label Encoding và One-Hot Encoding\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
        "features_encoded = pd.get_dummies(features, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Chuẩn hóa dữ liệu\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape dữ liệu cho LSTM\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Xây dựng mô hình LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, X_train_scaled.shape[1])))\n",
        "model.add(Dropout(0.5)) # Thêm lớp dropout để tránh overfitting\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "#Dùng early stopping để dừng quá trình huấn luyện khi độ chính xác trên tập kiểm tra ngừng cải thiện, giúp tránh overfitting.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  # Dừng sau 3 epochs không có cải thiện\n",
        "# Compile mô hình\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Đánh giá mô hình\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Độ chính xác của mô hình Long Short-Term Memory: {:.2f}\".format(accuracy))\n",
        "# Tính confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# In confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# In classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ZUNbOBKjoh",
        "outputId": "2333232f-773b-4dfc-dd3c-5b04ddada754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "103/103 [==============================] - 5s 7ms/step - loss: 0.4010 - accuracy: 0.8862 - val_loss: 0.2832 - val_accuracy: 0.8883\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.8953 - val_loss: 0.2370 - val_accuracy: 0.8981\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9017 - val_loss: 0.2160 - val_accuracy: 0.9090\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9083 - val_loss: 0.2097 - val_accuracy: 0.9005\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.1849 - accuracy: 0.9159 - val_loss: 0.2067 - val_accuracy: 0.9053\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.1755 - accuracy: 0.9196 - val_loss: 0.2091 - val_accuracy: 0.9029\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.1716 - accuracy: 0.9196 - val_loss: 0.2131 - val_accuracy: 0.9041\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.1656 - accuracy: 0.9241 - val_loss: 0.2157 - val_accuracy: 0.9066\n",
            "26/26 [==============================] - 0s 3ms/step\n",
            "Độ chính xác của mô hình Long Short-Term Memory: 0.91\n",
            "Confusion Matrix:\n",
            "[[708  24]\n",
            " [ 54  38]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       732\n",
            "           1       0.61      0.41      0.49        92\n",
            "\n",
            "    accuracy                           0.91       824\n",
            "   macro avg       0.77      0.69      0.72       824\n",
            "weighted avg       0.89      0.91      0.90       824\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ixZuAVRcpZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}